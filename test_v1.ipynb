{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Step 1: Load Dataset\n",
    "Step 2: Make Dataset Iterable\n",
    "Step 3: Create Model Class\n",
    "Step 4: Instantiate Model Class\n",
    "Step 5: Instantiate Loss Class\n",
    "Step 6: Instantiate Optimizer Class\n",
    "Step 7: Train Model\n",
    "https://www.deeplearningwizard.com/deep_learning/practical_pytorch/pytorch_lstm_neuralnetwork/\n",
    "\"\"\"\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as torch_data\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import pandas as pd\n",
    "from data_loader.dataloader import LSTMTSD_Dataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\" DONt CHANGE\n",
    "Parameters for LSTMModel_v0\n",
    "\"\"\"\n",
    "RATIO_SPLIT = 0.8\n",
    "batch_size = 200\n",
    "n_iters = 10000000\n",
    "seq_dim = 1\n",
    "iter = 0\n",
    "input_dim = 10\n",
    "hidden_dim = 100\n",
    "layer_dim = 1\n",
    "output_dim = 3\n",
    "learning_rate = 0.00001\n",
    "horizon = 1\n",
    "window_size= 5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Step 1: Load Dataset\n",
    "\n",
    "path = './dataset/'\n",
    "file_list = os.listdir(path)\n",
    "file_list_py = [file for file in file_list if file.endswith('.csv')] ## 파일명 끝이 .csv인 경우\n",
    "\n",
    "## csv 파일들을 DataFrame으로 불러와서 concat\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "df = pd.read_csv(\"./dataset/Telegram_1hour_7.csv\")\n",
    "df.insert(2, \"label\", int(0))\n",
    "df_0 = df[[\"Time\", \"Length\", \"label\"]].to_numpy()\n",
    "\n",
    "df = pd.read_csv(\"./dataset/Zoom_1hour_5.csv\")\n",
    "df.insert(2, \"label\", int(1))\n",
    "df_1 = df[[\"Time\", \"Length\", \"label\"]].to_numpy()\n",
    "\n",
    "df = pd.read_csv(\"./dataset/YouTube_1hour_2.csv\")\n",
    "df.insert(2, \"label\", int(2))\n",
    "df_2 = df[[\"Time\", \"Length\", \"label\"]].to_numpy()\n",
    "\n",
    "df_set = np.vstack((df_0, df_1, df_2))\n",
    "df_set = LSTMTSD_Dataset(df_set, window_size=window_size, horizon=horizon, normalize_method=\"z_score\")\n",
    "#dataloader = DataLoader(df_set, batch_size=1, drop_last=False, shuffle=True, num_workers=0)\n",
    "\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(df_set, [int(len(df_set)*RATIO_SPLIT),len(df_set) - int(len(df_set)*RATIO_SPLIT)])\n",
    "val_dataset, test_dataset = torch.utils.data.random_split(val_dataset, [int(len(val_dataset)*RATIO_SPLIT),len(val_dataset) - int(len(val_dataset)*RATIO_SPLIT)])\n",
    "\n",
    "print(\"train_dataset:\", len(train_dataset))\n",
    "print(\"val_dataset:\", len(val_dataset))\n",
    "print(\"test_dataset:\", len(test_dataset))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Step 2: Make Dataset Iterable\n",
    "\n",
    "num_epochs = int(n_iters / (len(train_dataset) / batch_size))\n",
    "#num_epochs = int(num_epochs)\n",
    "#num_epochs = 100\n",
    "print(int(num_epochs))\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, drop_last=False, shuffle=True, num_workers=0)\n",
    "val_loader   = DataLoader(dataset=val_dataset, batch_size=batch_size, drop_last=False, shuffle=True, num_workers=0)\n",
    "test_loader  = DataLoader(dataset=test_dataset, batch_size=batch_size, drop_last=False, shuffle=True, num_workers=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Step 3: Create Model Class\n",
    "class LSTMModel_v0(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(LSTMModel_v0, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "\n",
    "        # Readout layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()\n",
    "        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()\n",
    "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Step 4: Instantiate Model Class\n",
    "#model = LSTMModel(input_dim, hidden_dim, layer_dim, output_dim)\n",
    "model = LSTMModel_v0(input_dim, hidden_dim, layer_dim, output_dim)\n",
    "\n",
    "## Step 5: Instantiate Loss Class\n",
    "#criterion = nn.MSELoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "## Step 6: Instantiate Optimizer Class\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "len(list(model.parameters()))\n",
    "for i in range(len(list(model.parameters()))):\n",
    "    print(list(model.parameters())[i].size())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Step 7: Train Model\n",
    "# Number of steps to unroll\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, labels, _) in enumerate(train_loader):\n",
    "        inputs = inputs.view(-1, seq_dim, input_dim).requires_grad_()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs) #output: torch.Size([20, 1])\n",
    "        loss = criterion(outputs, labels.type(torch.LongTensor))\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        iter += 1\n",
    "        if iter % 50 == 0:\n",
    "            # Calculate Accuracy\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through  validation dataset\n",
    "            for inputs, labels, _ in val_loader:\n",
    "                inputs = inputs.view(-1, seq_dim, input_dim)\n",
    "                outputs = model(inputs) #torch.Size([20, 1])\n",
    "                _, predicted = torch.max(outputs.data, 1) #torch.Size([20])\n",
    "                total += labels.size(0)\n",
    "                predicted = predicted.resize(len(outputs), 1).type(torch.LongTensor) #torch.Size([20, 1])\n",
    "                correct += (predicted == labels).sum()\n",
    "\n",
    "            accuracy = 100 * correct / total\n",
    "\n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## CUDA\n",
    "\n",
    "#  Returns a bool indicating if CUDA is currently available.\n",
    "torch.cuda.is_available()\n",
    "#  True\n",
    "\n",
    "#  Returns the index of a currently selected device.\n",
    "torch.cuda.current_device()\n",
    "#  0\n",
    "\n",
    "#  Returns the number of GPUs available.\n",
    "torch.cuda.device_count()\n",
    "#  1\n",
    "\n",
    "#  Gets the name of a device.\n",
    "torch.cuda.get_device_name(0)\n",
    "#  'GeForce GTX 1060'\n",
    "\n",
    "#  Context-manager that changes the selected device.\n",
    "#  device (torch.device or int) – device index to select.\n",
    "torch.cuda.device(0)\n",
    "# Default CUDA device\n",
    "cuda = torch.device('cuda')\n",
    "\n",
    "iter = 0\n",
    "input_dim = 10\n",
    "hidden_dim = 100\n",
    "layer_dim = 1\n",
    "output_dim = 3\n",
    "learning_rate = 0.00001\n",
    "horizon = 1\n",
    "window_size= 5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--cpu', action='store_true',help='run in cpu')\n",
    "args = parser.parse_args()\n",
    "\n",
    "if args.cpu:\n",
    "    device = torch.device('cpu')\n",
    "else:\n",
    "    device = torch.device('cuda')\n",
    "\n",
    " x = torch.tensor([1., 2.]).to(device)\n",
    "\n",
    "## Step 1: Load Dataset\n",
    "df = pd.DataFrame()\n",
    "\n",
    "df = pd.read_csv(\"./dataset/Telegram_1hour_7.csv\")\n",
    "df.insert(2, \"label\", int(0))\n",
    "df_0 = df[[\"Time\", \"Length\", \"label\"]].to_numpy()\n",
    "\n",
    "df = pd.read_csv(\"./dataset/Zoom_1hour_5.csv\")\n",
    "df.insert(2, \"label\", int(1))\n",
    "df_1 = df[[\"Time\", \"Length\", \"label\"]].to_numpy()\n",
    "\n",
    "df = pd.read_csv(\"./dataset/YouTube_1hour_2.csv\")\n",
    "df.insert(2, \"label\", int(2))\n",
    "df_2 = df[[\"Time\", \"Length\", \"label\"]].to_numpy()\n",
    "\n",
    "df_set = np.vstack((df_0, df_1, df_2))\n",
    "cuda = torch.device('cuda')\n",
    "df_set = LSTMTSD_Dataset(df_set, window_size=window_size, horizon=horizon, normalize_method=\"z_score\")\n",
    "#dataloader = DataLoader(df_set, batch_size=1, drop_last=False, shuffle=True, num_workers=0)\n",
    "\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(df_set, [int(len(df_set)*RATIO_SPLIT),len(df_set) - int(len(df_set)*RATIO_SPLIT)])\n",
    "val_dataset, test_dataset = torch.utils.data.random_split(val_dataset, [int(len(val_dataset)*RATIO_SPLIT),len(val_dataset) - int(len(val_dataset)*RATIO_SPLIT)])\n",
    "\n",
    "print(\"train_dataset:\", len(train_dataset))\n",
    "print(\"val_dataset:\", len(val_dataset))\n",
    "print(\"test_dataset:\", len(test_dataset))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Step 2: Make Dataset Iterable\n",
    "\n",
    "num_epochs = int(n_iters / (len(train_dataset) / batch_size))\n",
    "#num_epochs = int(num_epochs)\n",
    "#num_epochs = 100\n",
    "print(int(num_epochs))\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, drop_last=False, shuffle=True, num_workers=0)\n",
    "val_loader   = DataLoader(dataset=val_dataset, batch_size=batch_size, drop_last=False, shuffle=True, num_workers=0)\n",
    "test_loader  = DataLoader(dataset=test_dataset, batch_size=batch_size, drop_last=False, shuffle=True, num_workers=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Step 3: Create Model Class\n",
    "class LSTMModel_v0(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(LSTMModel_v0, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "\n",
    "        # Readout layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()\n",
    "        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()\n",
    "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Step 4: Instantiate Model Class\n",
    "#model = LSTMModel(input_dim, hidden_dim, layer_dim, output_dim)\n",
    "model = LSTMModel_v0(input_dim, hidden_dim, layer_dim, output_dim)\n",
    "\n",
    "## Step 5: Instantiate Loss Class\n",
    "#criterion = nn.MSELoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "## Step 6: Instantiate Optimizer Class\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "len(list(model.parameters()))\n",
    "for i in range(len(list(model.parameters()))):\n",
    "    print(list(model.parameters())[i].size())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Step 7: Train Model\n",
    "# Number of steps to unroll\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, labels, _) in enumerate(train_loader):\n",
    "        inputs = inputs.view(-1, seq_dim, input_dim).requires_grad_()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs) #output: torch.Size([20, 1])\n",
    "        loss = criterion(outputs, labels.type(torch.LongTensor))\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        iter += 1\n",
    "        if iter % 50 == 0:\n",
    "            # Calculate Accuracy\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through  validation dataset\n",
    "            for inputs, labels, _ in val_loader:\n",
    "                inputs = inputs.view(-1, seq_dim, input_dim)\n",
    "                outputs = model(inputs) #torch.Size([20, 1])\n",
    "                _, predicted = torch.max(outputs.data, 1) #torch.Size([20])\n",
    "                total += labels.size(0)\n",
    "                predicted = predicted.resize(len(outputs), 1).type(torch.LongTensor) #torch.Size([20, 1])\n",
    "                correct += (predicted == labels).sum()\n",
    "\n",
    "            accuracy = 100 * correct / total\n",
    "\n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}